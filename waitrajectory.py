import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation, FFMpegWriter

class TrajectorySimulationAnimator:
    """
    A helper class to animate the results of a trajectory tracking simulation.

    This class visualizes three distinct paths and their states (position, velocity, orientation):
    1. The original, time-parameterized trajectory.
    2. The actual path taken by a simulated robot with physical limitations.
    3. The path of dynamically adjusted waypoints generated by the planner.
    """
    def __init__(self, original_states, adjusted_states, robot_positions, robot_velocities, robot_orientations):
        """
        Initializes the animator with detailed simulation data.
        
        Args:
            original_states (list): List of state tuples (t, x, v, a, theta, ...) for the ideal trajectory.
            adjusted_states (list): List of state tuples for the adjusted target waypoints.
            robot_positions (np.array): Nx3 array for the robot's actual path.
            robot_velocities (np.array): Nx3 array for the robot's actual velocity.
            robot_orientations (np.array): Nx3 array for the robot's actual orientation (Euler angles).
        """
        # Unpack states into separate arrays for easier access
        self.original_pos = np.array([s[1] for s in original_states])
        self.adjusted_pos = np.array([s[0] for s in adjusted_states])
        self.adjusted_vel = np.array([s[1] for s in adjusted_states])
        self.adjusted_theta = np.array([s[3] for s in adjusted_states])
        
        self.robot_pos = np.array(robot_positions)
        self.robot_vel = np.array(robot_velocities)
        self.robot_theta = np.array(robot_orientations)
        
        # Ensure all paths have the same number of frames for animation
        num_frames = len(self.robot_pos)
        if not (len(self.original_pos) == num_frames and len(self.adjusted_pos) == num_frames):
             # This check helps catch issues if the simulation loop and warm_start dt differ.
             min_len = min(len(self.original_pos), len(self.robot_pos), len(self.adjusted_pos))
             self.original_pos = self.original_pos[:min_len]
             self.robot_pos = self.robot_pos[:min_len]
             self.robot_vel = self.robot_vel[:min_len]
             self.robot_theta = self.robot_theta[:min_len]
             self.adjusted_pos = self.adjusted_pos[:min_len]
             self.adjusted_vel = self.adjusted_vel[:min_len]
             self.adjusted_theta = self.adjusted_theta[:min_len]

        self.fig = plt.figure(figsize=(10, 8))
        self.ax = self.fig.add_subplot(111, projection='3d')
        self.artists = {}
        self.arrows = [] # To hold quiver objects for removal

    def _rotation_matrix_from_euler(self, theta):
        # Helper function copied from TrajectoryPlanner3D
        roll, pitch, yaw = theta
        Rx = np.array([[1, 0, 0], [0, np.cos(roll), -np.sin(roll)], [0, np.sin(roll), np.cos(roll)]])
        Ry = np.array([[np.cos(pitch), 0, np.sin(pitch)], [0, 1, 0], [-np.sin(pitch), 0, np.cos(pitch)]])
        Rz = np.array([[np.cos(yaw), -np.sin(yaw), 0], [np.sin(yaw), np.cos(yaw), 0], [0, 0, 1]])
        return Rz @ Ry @ Rx
    
    def run(self, interval=50, save=False, filename='simulation_animation.mp4'):
        # ... (This method is unchanged)
        self._setup_plot()
        num_frames = len(self.robot_pos)
        anim = FuncAnimation(
            self.fig,
            self._update,
            frames=num_frames,
            interval=interval,
            blit=False
        )
        if save:
            writer = FFMpegWriter(fps=1000 // interval, metadata=dict(artist='Me'), bitrate=1800)
            anim.save(filename, writer=writer)
            print(f"Animation saved to {filename}")
        plt.show()

    def _setup_plot(self):
        # ... (This method is mostly unchanged, just updated labels)
        self.ax.set_xlabel('X')
        self.ax.set_ylabel('Y')
        self.ax.set_zlabel('Z')
        self.ax.set_title('Time-Scaling Simulation with Full State Visualization')

        all_points = np.vstack([self.original_pos, self.robot_pos, self.adjusted_pos])
        min_c, max_c = np.min(all_points, axis=0), np.max(all_points, axis=0)
        self.ax.set_xlim(min_c[0] - 1, max_c[0] + 1)
        self.ax.set_ylim(min_c[1] - 1, max_c[1] + 1)
        self.ax.set_zlim(min_c[2] - 1, max_c[2] + 1)
        self.ax.view_init(elev=20, azim=-135)

        self.ax.plot(self.original_pos[:, 0], self.original_pos[:, 1], self.original_pos[:, 2],
                     'k--', lw=1, alpha=0.5, label='Original Trajectory')
        self.ax.plot(self.robot_pos[:, 0], self.robot_pos[:, 1], self.robot_pos[:, 2],
                     'b-', lw=1.5, alpha=0.6, label="Robot's Path")
        
        self.artists['orig_point'], = self.ax.plot([], [], [], 'kx', markersize=8, label='Ideal Point')
        self.artists['robot_point'], = self.ax.plot([], [], [], 'bo', markersize=10, label='Robot')
        self.artists['adj_point'], = self.ax.plot([], [], [], 'gP', markersize=10, label='Adjusted Target')
        self.artists['target_line'], = self.ax.plot([], [], [], 'r-', lw=1, alpha=0.8)
        self.ax.legend()

    def _update(self, frame):
        """Update function for FuncAnimation, now with vectors."""
        # Clear all arrows from the previous frame
        for arrow in self.arrows:
            arrow.remove()
        self.arrows.clear()

        # --- CORRECTED SECTION ---
        # Get the position data for the current frame
        orig_pos = self.original_pos[frame]
        robot_pos = self.robot_pos[frame]
        adj_pos = self.adjusted_pos[frame]

        # Update points by passing each coordinate as a single-element list
        self.artists['orig_point'].set_data_3d([orig_pos[0]], [orig_pos[1]], [orig_pos[2]])
        self.artists['robot_point'].set_data_3d([robot_pos[0]], [robot_pos[1]], [robot_pos[2]])
        self.artists['adj_point'].set_data_3d([adj_pos[0]], [adj_pos[1]], [adj_pos[2]])
        # --- END CORRECTED SECTION ---

        # Update connecting line (this was already correct)
        line_data = np.transpose([robot_pos, adj_pos])
        self.artists['target_line'].set_data_3d(line_data[0], line_data[1], line_data[2])

        # --- Draw Robot Vectors ---
        r_vel, r_theta = self.robot_vel[frame], self.robot_theta[frame]
        # Robot Velocity
        self.arrows.append(self.ax.quiver(*robot_pos, *r_vel, color='blue', linestyle='dashed', length=0.5, normalize=True))
        # Robot Orientation
        R_robot = self._rotation_matrix_from_euler(r_theta)
        robot_axis_colors = ['cyan', 'magenta', 'yellow']
        for i in range(3):
            self.arrows.append(self.ax.quiver(*robot_pos, *R_robot[:, i], color=robot_axis_colors[i], length=0.4))
            
        # --- Draw Adjusted Target Vectors ---
        a_vel, a_theta = self.adjusted_vel[frame], self.adjusted_theta[frame]
        # Target Velocity
        self.arrows.append(self.ax.quiver(*adj_pos, *a_vel, color='green', linestyle='dashed', length=0.5, normalize=True))
        # Target Orientation
        R_adj = self._rotation_matrix_from_euler(a_theta)
        adj_axis_colors = ['red', 'green', 'blue'] # Standard RGB for desired frame
        for i in range(3):
            self.arrows.append(self.ax.quiver(*adj_pos, *R_adj[:, i], color=adj_axis_colors[i], length=0.7))

        return list(self.artists.values()) + self.arrows


class TrajectoryPlanner3D:
    # Added time_scaling_gain parameter and new state variables
    def __init__(self, init_type, time_scaling_gain=0.5, **kwargs):
        self.init_type = init_type
        self.traj = None
        self.fig = None
        self.ax = None
        
        # --- NEW: State for Dynamic Time Scaling ---
        self.time_scaling_gain = time_scaling_gain # Kp gain
        self.virtual_t = 0.0  # The planner's internal, adjusted time
        self.last_real_t = 0.0 # Last real time stamp seen by get()
        # --- END NEW ---

        if init_type == 'equations':
            self.pos_func = kwargs['pos_func']
            self.vel_func = kwargs['vel_func']
            self.acc_func = kwargs.get('acc_func', None)
            self.angle_func = kwargs['angle_func']
            self.omega_func = kwargs['omega_func']
            self.alpha_func = kwargs.get('alpha_func', None)
        elif init_type == 'quintic_polynomial':
            self.waypoints = kwargs['waypoints']
            # Get the start time from the first waypoint
            if self.waypoints:
                self.virtual_t = self.waypoints[0][-1]
                self.last_real_t = self.waypoints[0][-1]
            self._compute_quintic_coeffs()
        else:
            raise ValueError('Unknown initialization type')

    def _compute_quintic_coeffs(self):
        # ... (no changes in this method)
        # Each waypoint: (pos, vel, acc, angles, omega, alpha, time)
        self.coeffs_pos = []
        self.coeffs_ang = []
        for i in range(len(self.waypoints) - 1):
            p0, v0, a0, th0, w0, al0, t0 = self.waypoints[i]
            p1, v1, a1, th1, w1, al1, t1 = self.waypoints[i + 1]
            M = np.array([
                [1, t0, t0**2, t0**3, t0**4, t0**5],
                [0, 1, 2*t0, 3*t0**2, 4*t0**3, 5*t0**4],
                [0, 0, 2, 6*t0, 12*t0**2, 20*t0**3],
                [1, t1, t1**2, t1**3, t1**4, t1**5],
                [0, 1, 2*t1, 3*t1**2, 4*t1**3, 5*t1**4],
                [0, 0, 2, 6*t1, 12*t1**2, 20*t1**3]
            ])

            coeffs_axis_p = []
            coeffs_axis_th = []
            for j in range(3):
                b_p = np.hstack([p0[j], v0[j], a0[j], p1[j], v1[j], a1[j]])
                b_th = np.hstack([th0[j], w0[j], al0[j], th1[j], w1[j], al1[j]])
                coeffs_axis_p.append(np.linalg.solve(M, b_p))
                coeffs_axis_th.append(np.linalg.solve(M, b_th))
            self.coeffs_pos.append((np.array(coeffs_axis_p), (t0, t1)))
            self.coeffs_ang.append((np.array(coeffs_axis_th), (t0, t1)))


    def _eval_quintic(self, t, coeffs):
        # ... (no changes in this method)
        for coeff, (t0, t1) in coeffs:
            if t0 <= t <= t1:
                T = np.array([1, t, t**2, t**3, t**4, t**5])
                dT = np.array([0, 1, 2*t, 3*t**2, 4*t**3, 5*t**4])
                ddT = np.array([0, 0, 2, 6*t, 12*t**2, 20*t**3])
                pos = coeff @ T
                vel = coeff @ dT
                acc = coeff @ ddT
                return pos, vel, acc
        # Handle t outside the defined range (e.g., return the state at the end point)
        coeff, (t0, t1) = coeffs[-1]
        t_eval = max(t0, min(t, t1)) # Clamp t to the last segment
        T = np.array([1, t_eval, t_eval**2, t_eval**3, t_eval**4, t_eval**5])
        dT = np.array([0, 1, 2*t_eval, 3*t_eval**2, 4*t_eval**3, 5*t_eval**4])
        ddT = np.array([0, 0, 2, 6*t_eval, 12*t_eval**2, 20*t_eval**3])
        return coeff @ T, coeff @ dT, coeff @ ddT


    # --- RENAMED: This is the original get method ---
    def _get_at_time(self, t):
        """Gets the raw trajectory state at a specific time t."""
        if self.init_type == 'equations':
            x = self.pos_func(t)
            v = self.vel_func(t)
            a = self.acc_func(t) if self.acc_func else np.zeros(3)
            theta = self.angle_func(t)
            omega = self.omega_func(t)
            alpha = self.alpha_func(t) if self.alpha_func else np.zeros(3)
        else: # quintic_polynomial
            x, v, a = self._eval_quintic(t, self.coeffs_pos)
            theta, omega, alpha = self._eval_quintic(t, self.coeffs_ang)
        return x, v, a, theta, omega, alpha

    # --- NEW: The main get method with time scaling logic ---
    def get(self, t, robot_pos=None):
        """
        Obtain the desired waypoint at real time t.
        
        If robot_pos is provided, it dynamically adjusts the progression along
        the trajectory to help the robot keep up.
        
        Args:
            t (float): The current real-world time.
            robot_pos (np.array, optional): The robot's current 3D position. 
                                            Defaults to None.

        Returns:
            tuple: The desired state (x, v, a, theta, omega, alpha) for the robot.
        """
        # If no robot state is given, just behave as before but using virtual time.
        if robot_pos is None:
            # We still advance virtual_t by real_t's delta to keep it moving
            dt = t - self.last_real_t
            self.virtual_t += dt
            self.last_real_t = t
            return self._get_at_time(self.virtual_t)

        # --- Dynamic Time Scaling Logic ---
        # 1. Get the desired state at the current virtual time
        p_desired, v_desired, _, _, _, _ = self._get_at_time(self.virtual_t)

        # 2. Calculate the "along-path" error
        error_vec = p_desired - robot_pos
        v_norm = np.linalg.norm(v_desired)
        
        e_along_path = 0.0
        if v_norm > 1e-6: # Avoid division by zero if velocity is zero
            v_dir = v_desired / v_norm
            e_along_path = np.dot(error_vec, v_dir)
        
        # 3. Calculate the time scaling factor and update virtual time
        dt = t - self.last_real_t
        scale = 1.0 - self.time_scaling_gain * e_along_path
        
        # Prevent time from going backwards or jumping too far ahead
        scale = np.clip(scale, 0.0, 2.0)
        
        self.virtual_t += scale * dt
        self.last_real_t = t

        # 4. Return the waypoint at the new virtual time
        return self._get_at_time(self.virtual_t)


    def warm_start(self, dt, total_time):
        self.traj = []
        # --- NEW: Reset time state on warm_start ---
        self.virtual_t = 0.0
        if self.init_type == 'quintic_polynomial' and self.waypoints:
            self.virtual_t = self.waypoints[0][-1]
        self.last_real_t = self.virtual_t
        
        # Use a temporary variable for time to not mess with the class state
        time_iter = self.virtual_t
        end_time = time_iter + total_time
        while time_iter <= end_time:
            self.traj.append((time_iter, *self._get_at_time(time_iter)))
            time_iter += dt
            
        return self.traj

    # ... (No changes to plotting and animation methods)
    def setup_plot(self):
        self.fig = plt.figure()
        self.ax = self.fig.add_subplot(111, projection='3d')
        self.ax.set_xlabel('X')
        self.ax.set_ylabel('Y')
        self.ax.set_zlabel('Z')
        self.ax.set_title('3D Trajectory Animation')

    def _rotation_matrix_from_euler(self, theta):
        roll, pitch, yaw = theta
        Rx = np.array([[1, 0, 0], [0, np.cos(roll), -np.sin(roll)], [0, np.sin(roll), np.cos(roll)]])
        Ry = np.array([[np.cos(pitch), 0, np.sin(pitch)], [0, 1, 0], [-np.sin(pitch), 0, np.cos(pitch)]])
        Rz = np.array([[np.cos(yaw), -np.sin(yaw), 0], [np.sin(yaw), np.cos(yaw), 0], [0, 0, 1]])
        return Rz @ Ry @ Rx

    def plot_state(self, t):
        x, v, a, theta, omega, alpha = self._get_at_time(t)
        self.ax.scatter(*x, color='r', s=50)
        self.ax.quiver(*x, *v, color='k', linestyle='dashed', length=0.5, normalize=True)
        R = self._rotation_matrix_from_euler(theta)
        colors = ['r', 'g', 'b']
        for i in range(3):
            self.ax.quiver(*x, *R[:, i], color=colors[i], length=0.7, normalize=True)

    def animate(self, interval=50, save=False, filename='trajectory.mp4'):
        if self.traj is None:
            raise RuntimeError('Run warm_start() before animate().')

        self.setup_plot()
        pos = np.array([x[1] for x in self.traj])
        line, = self.ax.plot([], [], [], 'gray', lw=1)
        point, = self.ax.plot([], [], [], 'ro')
        self.arrows = []

        def init():
            self.ax.set_xlim(np.min(pos[:,0])-1, np.max(pos[:,0])+1)
            self.ax.set_ylim(np.min(pos[:,1])-1, np.max(pos[:,1])+1)
            self.ax.set_zlim(np.min(pos[:,2])-1, np.max(pos[:,2])+1)
            return line, point

        def update(frame):
            t, x, v, a, theta, omega, alpha = self.traj[frame]
            line.set_data(pos[:frame+1,0], pos[:frame+1,1])
            line.set_3d_properties(pos[:frame+1,2])
            point.set_data([x[0]], [x[1]])
            point.set_3d_properties([x[2]])
            
            for arrow in self.arrows:
                arrow.remove()
            self.arrows.clear()

            vel_arrow = self.ax.quiver(*x, *v, color='k', linestyle='dashed', length=0.5, normalize=True)
            R = self._rotation_matrix_from_euler(theta)
            colors = ['r', 'g', 'b']
            for i in range(3):
                self.arrows.append(self.ax.quiver(*x, *R[:, i], color=colors[i], length=0.7, normalize=True))
            self.arrows.append(vel_arrow)

            return line, point, *self.arrows

        anim = FuncAnimation(self.fig, update, frames=len(self.traj), init_func=init, interval=interval, blit=False)
        if save:
            writer = FFMpegWriter(fps=1000//interval)
            anim.save(filename, writer=writer)
        plt.show()


if __name__ == '__main__':
    # --- Original Examples remain unchanged ---
    # Example 1: Equation-based trajectory
    print("\nRunning simulation to demonstrate Equation-based trajectory...")
    pos_func = lambda t: np.array([np.cos(t), np.sin(t), 0.1*t])
    vel_func = lambda t: np.array([-np.sin(t), np.cos(t), 0.1])
    angle_func = lambda t: np.array([0, 0, t + np.pi/2])
    omega_func = lambda t: np.array([0, 0, 1])

    planner_eq = TrajectoryPlanner3D('equations',
                                      pos_func=pos_func,
                                      vel_func=vel_func,
                                      angle_func=angle_func,
                                      omega_func=omega_func)
    planner_eq.warm_start(dt=0.1, total_time=10)
    planner_eq.animate(save=False)

    # Example 2: Quintic polynomial trajectory
    print("\nRunning simulation to demonstrate Quintic Polynomial trajectory...")
    waypoints = [
        (np.array([0,0,0]), np.array([0.5,0,0]), np.array([0,0,0]), np.array([0,0,0]), np.array([0,0,np.pi/2]), np.array([0,0,0]), 0),
        (np.array([1,2,1]), np.array([0.2,0.1,0]), np.array([0,0,0]), np.array([0,0,np.pi/2]), np.array([0,0,np.pi]), np.array([0,0,0]), 2),
        (np.array([2,0,2]), np.array([0,0,0]), np.array([0,0,0]), np.array([0,0,np.pi]), np.array([0,0,0]), np.array([0,0,0]), 4)
    ] 

    planner_poly = TrajectoryPlanner3D('quintic_polynomial', waypoints=waypoints, time_scaling_gain=0.8)
    planner_poly.warm_start(dt=0.1, total_time=4)
    planner_poly.animate(save=False)


    # --- Example 3: Demonstrate Time Scaling ---
    print("\nRunning simulation to demonstrate dynamic time scaling...")
    
    # Let's use the quintic planner
    planner = planner_poly
    
    # Simulate a "slow" robot that can only move at a max speed
    robot_pos = waypoints[0][0].astype('float64').copy()
    robot_vel = np.array([0.0, 0.0, 0.0])
    robot_theta = waypoints[0][3].astype('float64').copy()
    max_robot_speed = 0.5
    
    dt = 0.05
    total_time = waypoints[-1][-1]

    # --- Run the enhanced simulation loop ---
    # Store history of all relevant states
    robot_pos_history = [robot_pos.copy()]
    robot_vel_history = [robot_vel.copy()]
    robot_theta_history = [robot_theta.copy()]
    adjusted_state_history = [planner._get_at_time(0)[0:4]] # (pos, vel, acc, theta)

    # planner.warm_start(0, 0) # Reset planner's internal time

    time_steps = np.arange(dt, total_time + dt, dt)
    for t in time_steps:
        # Get the next waypoint from the planner
        desired_state = planner.get(t, robot_pos=robot_pos)
        desired_pos, desired_vel, _, desired_theta, _, _ = desired_state
        
        # Simulate the robot's movement
        move_dir = desired_pos - robot_pos
        dist_to_target = np.linalg.norm(move_dir)
        step_dist = min(max_robot_speed * dt, dist_to_target)
        
        if dist_to_target > 1e-6:
            robot_vel = (step_dist / dt) * (move_dir / dist_to_target)
            robot_pos += robot_vel * dt
        else:
            robot_vel = np.array([0.0, 0.0, 0.0])

        # For visualization, assume robot orientation instantly matches the target's
        robot_theta = desired_theta
        
        # Append current states to history
        robot_pos_history.append(robot_pos.copy())
        robot_vel_history.append(robot_vel.copy())
        robot_theta_history.append(robot_theta.copy())
        adjusted_state_history.append(desired_state[0:4]) # Store pos, vel, acc, theta

    # --- Prepare data and launch the animator ---
    # 1. Get the original (ideal) trajectory states
    planner.warm_start(dt, total_time)
    original_states = planner.traj

    # --- Launch the animator ---
    animator = TrajectorySimulationAnimator(
        original_states=original_states,
        adjusted_states=adjusted_state_history,
        robot_positions=robot_pos_history,
        robot_velocities=robot_vel_history,
        robot_orientations=robot_theta_history
    )
    animator.run(interval=40, save=False, filename='full_state_simulation.mp4')